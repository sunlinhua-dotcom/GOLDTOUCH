
import os
import asyncio
from tradingagents.llm_adapters.google_openai_adapter import ChatGoogleOpenAI

from dotenv import load_dotenv

# åŠ è½½çœŸå®ç¯å¢ƒé…ç½®
load_dotenv(".env")

api_key = os.getenv("GOOGLE_API_KEY")
base_url = os.getenv("CUSTOM_OPENAI_BASE_URL")

print(f"ğŸ”§ Testing ChatGoogleOpenAI with:")
print(f"   API Key: {api_key[:10]}...")
print(f"   Base URL: {base_url}")

# å®ä¾‹åŒ– Adapter
llm = ChatGoogleOpenAI(
    model="gemini-3-pro-preview",
    google_api_key=api_key,
    base_url=base_url,
    transport="rest"
)

async def test_invoke():
    try:
        print("ğŸš€ Sending request...")
        # å°è¯•å‘é€è¯·æ±‚ï¼Œå³ä½¿å¤±è´¥ä¹Ÿèƒ½çœ‹åˆ°åº•å±‚çš„æŠ¥é”™URL
        response = await llm.ainvoke("Hello")
        print(f"âœ… Response: {response.content}")
    except Exception as e:
        print(f"âŒ Error: {e}")
        # å°è¯•ä»å¼‚å¸¸ä¸­æå–æ›´å¤šä¿¡æ¯
        if hasattr(e, 'response'):
             print(f"ğŸ“¥ Error Response: {e.response}")

if __name__ == "__main__":
    asyncio.run(test_invoke())
