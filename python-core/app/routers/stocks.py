"""
è‚¡ç¥¨è¯¦æƒ…ç›¸å…³API
- ç»Ÿä¸€å“åº”åŒ…: {success, data, message, timestamp}
- æ‰€æœ‰ç«¯ç‚¹å‡éœ€é‰´æƒ (Bearer Token)
- è·¯å¾„å‰ç¼€åœ¨ main.py ä¸­æŒ‚è½½ä¸º /apiï¼Œå½“å‰è·¯ç”±è‡ªèº«å‰ç¼€ä¸º /stocks
"""
from typing import Optional, Dict, Any, List, Tuple
from fastapi import APIRouter, Depends, HTTPException, status, Query
import logging
import re

from app.routers.auth_db import get_current_user
from app.core.database import get_mongo_db
from app.core.database import get_mongo_db
from app.core.response import ok
import asyncio
import akshare as ak

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/stocks", tags=["stocks"])


def _zfill_code(code: str) -> str:
    try:
        s = str(code).strip()
        if len(s) == 6 and s.isdigit():
            return s
        return s.zfill(6)
    except Exception:
        return str(code)


def _detect_market_and_code(code: str) -> Tuple[str, str]:
    """
    æ£€æµ‹è‚¡ç¥¨ä»£ç çš„å¸‚åœºç±»å‹å¹¶æ ‡å‡†åŒ–ä»£ç 

    Args:
        code: è‚¡ç¥¨ä»£ç 

    Returns:
        (market, normalized_code): å¸‚åœºç±»å‹å’Œæ ‡å‡†åŒ–åçš„ä»£ç 
            - CN: Aè‚¡ï¼ˆ6ä½æ•°å­—ï¼‰
            - HK: æ¸¯è‚¡ï¼ˆ4-5ä½æ•°å­—æˆ–å¸¦.HKåç¼€ï¼‰
            - US: ç¾è‚¡ï¼ˆå­—æ¯ä»£ç ï¼‰
    """
    code = code.strip().upper()

    # æ¸¯è‚¡ï¼šå¸¦.HKåç¼€
    if code.endswith('.HK'):
        return ('HK', code[:-3].zfill(5))  # ç§»é™¤.HKï¼Œè¡¥é½åˆ°5ä½

    # ç¾è‚¡ï¼šçº¯å­—æ¯
    if re.match(r'^[A-Z]+$', code):
        return ('US', code)

    # æ¸¯è‚¡ï¼š4-5ä½æ•°å­—
    if re.match(r'^\d{4,5}$', code):
        return ('HK', code.zfill(5))  # è¡¥é½åˆ°5ä½

    # Aè‚¡ï¼š6ä½æ•°å­—
    if re.match(r'^\d{6}$', code):
        return ('CN', code)

    # é»˜è®¤å½“ä½œAè‚¡å¤„ç†
    return ('CN', _zfill_code(code))


@router.get("/{code}/quote", response_model=dict)
async def get_quote(
    code: str,
    force_refresh: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰"),
    current_user: dict = Depends(get_current_user)
):
    """
    è·å–è‚¡ç¥¨å®æ—¶è¡Œæƒ…ï¼ˆæ”¯æŒAè‚¡/æ¸¯è‚¡/ç¾è‚¡ï¼‰

    è‡ªåŠ¨è¯†åˆ«å¸‚åœºç±»å‹ï¼š
    - 6ä½æ•°å­— â†’ Aè‚¡
    - 4ä½æ•°å­—æˆ–.HK â†’ æ¸¯è‚¡
    - çº¯å­—æ¯ â†’ ç¾è‚¡

    å‚æ•°ï¼š
    - code: è‚¡ç¥¨ä»£ç 
    - force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰

    è¿”å›å­—æ®µï¼ˆdataå†…ï¼Œè›‡å½¢å‘½åï¼‰:
      - code, name, market
      - price(close), change_percent(pct_chg), amount, prev_close(ä¼°ç®—)
      - turnover_rate, amplitudeï¼ˆæŒ¯å¹…ï¼Œæ›¿ä»£é‡æ¯”ï¼‰
      - trade_date, updated_at
    """
    # æ£€æµ‹å¸‚åœºç±»å‹
    market, normalized_code = _detect_market_and_code(code)

    # æ¸¯è‚¡å’Œç¾è‚¡ï¼šä½¿ç”¨æ–°æœåŠ¡
    if market in ['HK', 'US']:
        from app.services.foreign_stock_service import ForeignStockService

        db = get_mongo_db()  # ä¸éœ€è¦ awaitï¼Œç›´æ¥è¿”å›æ•°æ®åº“å¯¹è±¡
        service = ForeignStockService(db=db)

        try:
            quote = await service.get_quote(market, normalized_code, force_refresh)
            return ok(data=quote)
        except Exception as e:
            logger.error(f"è·å–{market}è‚¡ç¥¨{code}è¡Œæƒ…å¤±è´¥: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"è·å–è¡Œæƒ…å¤±è´¥: {str(e)}"
            )

    # Aè‚¡ï¼šä½¿ç”¨ç°æœ‰é€»è¾‘
    db = get_mongo_db()
    code6 = normalized_code

    # è¡Œæƒ…
    q = await db["market_quotes"].find_one({"code": code6}, {"_id": 0})

    # ğŸ”¥ è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹æŸ¥è¯¢ç»“æœ
    logger.info(f"ğŸ” æŸ¥è¯¢ market_quotes: code={code6}")
    if q:
        logger.info(f"  âœ… æ‰¾åˆ°æ•°æ®: volume={q.get('volume')}, amount={q.get('amount')}, volume_ratio={q.get('volume_ratio')}")
    else:
        logger.info(f"  âŒ æœªæ‰¾åˆ°æ•°æ®")

    # ğŸ”¥ åŸºç¡€ä¿¡æ¯ - æŒ‰æ•°æ®æºä¼˜å…ˆçº§æŸ¥è¯¢
    from app.core.unified_config import UnifiedConfigManager
    config = UnifiedConfigManager()
    data_source_configs = await config.get_data_source_configs_async()

    # æå–å¯ç”¨çš„æ•°æ®æºï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
    enabled_sources = [
        ds.type.lower() for ds in data_source_configs
        if ds.enabled and ds.type.lower() in ['tushare', 'akshare', 'baostock']
    ]

    if not enabled_sources:
        enabled_sources = ['tushare', 'akshare', 'baostock']

    # æŒ‰ä¼˜å…ˆçº§æŸ¥è¯¢åŸºç¡€ä¿¡æ¯
    b = None
    for src in enabled_sources:
        b = await db["stock_basic_info"].find_one({"code": code6, "source": src}, {"_id": 0})
        if b:
            break

    # å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½æ²¡æœ‰ï¼Œå°è¯•ä¸å¸¦ source æ¡ä»¶æŸ¥è¯¢ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
    if not b:
        b = await db["stock_basic_info"].find_one({"code": code6}, {"_id": 0})

    if not q and not b:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨çš„ä»»ä½•ä¿¡æ¯")

    close = (q or {}).get("close")
    pct = (q or {}).get("pct_chg")
    pre_close_saved = (q or {}).get("pre_close")
    prev_close = pre_close_saved
    if prev_close is None:
        try:
            if close is not None and pct is not None:
                prev_close = round(float(close) / (1.0 + float(pct) / 100.0), 4)
        except Exception:
            prev_close = None

    # ğŸ”¥ ä¼˜å…ˆä» market_quotes è·å– turnover_rateï¼ˆå®æ—¶æ•°æ®ï¼‰
    # å¦‚æœ market_quotes ä¸­æ²¡æœ‰ï¼Œå†ä» stock_basic_info è·å–ï¼ˆæ—¥åº¦æ•°æ®ï¼‰
    turnover_rate = (q or {}).get("turnover_rate")
    turnover_rate_date = None
    if turnover_rate is None:
        turnover_rate = (b or {}).get("turnover_rate")
        turnover_rate_date = (b or {}).get("trade_date")  # æ¥è‡ªæ—¥åº¦æ•°æ®
    else:
        turnover_rate_date = (q or {}).get("trade_date")  # æ¥è‡ªå®æ—¶æ•°æ®

    # ğŸ”¥ è®¡ç®—æŒ¯å¹…ï¼ˆamplitudeï¼‰æ›¿ä»£é‡æ¯”ï¼ˆvolume_ratioï¼‰
    # æŒ¯å¹… = (æœ€é«˜ä»· - æœ€ä½ä»·) / æ˜¨æ”¶ä»· Ã— 100%
    amplitude = None
    amplitude_date = None
    try:
        high = (q or {}).get("high")
        low = (q or {}).get("low")
        logger.info(f"ğŸ” è®¡ç®—æŒ¯å¹…: high={high}, low={low}, prev_close={prev_close}")
        if high is not None and low is not None and prev_close is not None and prev_close > 0:
            amplitude = round((float(high) - float(low)) / float(prev_close) * 100, 2)
            amplitude_date = (q or {}).get("trade_date")  # æ¥è‡ªå®æ—¶æ•°æ®
            logger.info(f"  âœ… æŒ¯å¹…è®¡ç®—æˆåŠŸ: {amplitude}%")
        else:
            logger.warning(f"  âš ï¸ æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•è®¡ç®—æŒ¯å¹…")
    except Exception as e:
        logger.warning(f"  âŒ è®¡ç®—æŒ¯å¹…å¤±è´¥: {e}")
        amplitude = None

    data = {
        "code": code6,
        "name": (b or {}).get("name"),
        "market": (b or {}).get("market"),
        "price": close,
        "change_percent": pct,
        "amount": (q or {}).get("amount"),
        "volume": (q or {}).get("volume"),
        "open": (q or {}).get("open"),
        "high": (q or {}).get("high"),
        "low": (q or {}).get("low"),
        "prev_close": prev_close,
        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨å®æ—¶æ•°æ®ï¼Œé™çº§åˆ°æ—¥åº¦æ•°æ®
        "turnover_rate": turnover_rate,
        "amplitude": amplitude,  # ğŸ”¥ æ–°å¢ï¼šæŒ¯å¹…ï¼ˆæ›¿ä»£é‡æ¯”ï¼‰
        "turnover_rate_date": turnover_rate_date,  # ğŸ”¥ æ–°å¢ï¼šæ¢æ‰‹ç‡æ•°æ®æ—¥æœŸ
        "amplitude_date": amplitude_date,  # ğŸ”¥ æ–°å¢ï¼šæŒ¯å¹…æ•°æ®æ—¥æœŸ
        "trade_date": (q or {}).get("trade_date"),
        "updated_at": (q or {}).get("updated_at"),
    }

    return ok(data)


@router.get("/{code}/fundamentals", response_model=dict)
async def get_fundamentals(
    code: str,
    source: Optional[str] = Query(None, description="æ•°æ®æº (tushare/akshare/baostock/multi_source)"),
    force_refresh: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰"),
    # current_user: dict = Depends(get_current_user)  # å¼€å‘ç¯å¢ƒæš‚æ—¶ç¦ç”¨è®¤è¯
):
    """
    è·å–åŸºç¡€é¢å¿«ç…§ï¼ˆæ”¯æŒAè‚¡/æ¸¯è‚¡/ç¾è‚¡ï¼‰

    æ•°æ®æ¥æºä¼˜å…ˆçº§ï¼š
    1. stock_basic_info é›†åˆï¼ˆåŸºç¡€ä¿¡æ¯ã€ä¼°å€¼æŒ‡æ ‡ï¼‰
    2. stock_financial_data é›†åˆï¼ˆè´¢åŠ¡æŒ‡æ ‡ï¼šROEã€è´Ÿå€ºç‡ç­‰ï¼‰

    å‚æ•°ï¼š
    - code: è‚¡ç¥¨ä»£ç 
    - source: æ•°æ®æºï¼ˆå¯é€‰ï¼‰ï¼Œé»˜è®¤æŒ‰ä¼˜å…ˆçº§ï¼štushare > multi_source > akshare > baostock
    - force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰
    """
    # æ£€æµ‹å¸‚åœºç±»å‹
    market, normalized_code = _detect_market_and_code(code)

    # æ¸¯è‚¡å’Œç¾è‚¡ï¼šä½¿ç”¨æ–°æœåŠ¡
    if market in ['HK', 'US']:
        from app.services.foreign_stock_service import ForeignStockService

        db = get_mongo_db()  # ä¸éœ€è¦ awaitï¼Œç›´æ¥è¿”å›æ•°æ®åº“å¯¹è±¡
        service = ForeignStockService(db=db)

        try:
            info = await service.get_basic_info(market, normalized_code, force_refresh)
            return ok(data=info)
        except Exception as e:
            logger.error(f"è·å–{market}è‚¡ç¥¨{code}åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"è·å–åŸºç¡€ä¿¡æ¯å¤±è´¥: {str(e)}"
            )

    # Aè‚¡ï¼šä½¿ç”¨ç°æœ‰é€»è¾‘
    db = get_mongo_db()
    code6 = normalized_code

    # 1. è·å–åŸºç¡€ä¿¡æ¯ï¼ˆæ”¯æŒæ•°æ®æºç­›é€‰ï¼‰
    query = {"code": code6}

    if source:
        # æŒ‡å®šæ•°æ®æº
        query["source"] = source
        b = await db["stock_basic_info"].find_one(query, {"_id": 0})
        if not b:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨åœ¨æ•°æ®æº {source} ä¸­çš„åŸºç¡€ä¿¡æ¯"
            )
    else:
        # ğŸ”¥ æœªæŒ‡å®šæ•°æ®æºï¼ŒæŒ‰ä¼˜å…ˆçº§æŸ¥è¯¢
        source_priority = ["tushare", "multi_source", "akshare", "baostock"]
        b = None

        for src in source_priority:
            query_with_source = {"code": code6, "source": src}
            b = await db["stock_basic_info"].find_one(query_with_source, {"_id": 0})
            if b:
                logger.info(f"âœ… ä½¿ç”¨æ•°æ®æº: {src} æŸ¥è¯¢è‚¡ç¥¨ {code6}")
                break

        # å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½æ²¡æœ‰ï¼Œå°è¯•ä¸å¸¦ source æ¡ä»¶æŸ¥è¯¢ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        if not b:
            b = await db["stock_basic_info"].find_one({"code": code6}, {"_id": 0})
            if b:
                logger.warning(f"âš ï¸ ä½¿ç”¨æ—§æ•°æ®ï¼ˆæ—  source å­—æ®µï¼‰: {code6}")

        # ğŸ”¥ æ•°æ®åº“æ— æ•°æ®æ—¶ï¼Œå®æ—¶ä» AKShare è·å–
        if not b:
            logger.warning(f"âš ï¸ æ•°æ®åº“æ— æ•°æ®ï¼Œå°è¯•å®æ—¶ä» AKShare è·å–: {code6}")
            try:
                from tradingagents.dataflows.providers.china.akshare import AKShareProvider

                akshare = AKShareProvider()

                # è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å’Œå®æ—¶è¡Œæƒ…ï¼ˆåŒ…å« PEã€PBã€å¸‚å€¼ç­‰æŒ‡æ ‡ï¼‰
                stock_quotes = await akshare.get_stock_quotes(code6)

                if stock_quotes:
                    b = {
                        "code": code6,
                        "name": stock_quotes.get("name", f"è‚¡ç¥¨{code6}"),
                        "industry": "",  # å®æ—¶æ¥å£ä¸æä¾›è¡Œä¸šä¿¡æ¯
                        "market": "ä¸»æ¿",  # é»˜è®¤ä¸»æ¿
                        "pe": stock_quotes.get("pe"),  # ğŸ”¥ å®æ—¶ PE
                        "pe_ttm": stock_quotes.get("pe_ttm"),  # ğŸ”¥ å®æ—¶ PE TTM
                        "pb": stock_quotes.get("pb"),  # ğŸ”¥ å®æ—¶ PB
                        "total_mv": stock_quotes.get("market_cap"),  # ğŸ”¥ å®æ—¶å¸‚å€¼
                        "source": "akshare_realtime"
                    }

                    # ğŸ”¥ å¦‚æœå®æ—¶PE/PBä¸ºç©ºï¼Œå°è¯•ä»å†å²æ•°æ®è·å–æœ€è¿‘çš„PE/PB
                    if not b.get("pe") or not b.get("pb"):
                        logger.info(f"âš ï¸ å®æ—¶PE/PBä¸ºç©ºï¼Œå°è¯•è·å–å†å²æ•°æ®: {code6}")
                        try:
                            # ä» stock_daily_quotes è·å–æœ€è¿‘çš„PE/PBæ•°æ®
                            historical_quote = await db["stock_daily_quotes"].find_one(
                                {"code": code6},
                                {"pe": 1, "pb": 1, "pe_ttm": 1, "trade_date": 1},
                                sort=[("trade_date", -1)]
                            )
                            if historical_quote:
                                if not b.get("pe") and historical_quote.get("pe"):
                                    b["pe"] = historical_quote["pe"]
                                    b["pe_source"] = f"historical_{historical_quote.get('trade_date')}"
                                if not b.get("pb") and historical_quote.get("pb"):
                                    b["pb"] = historical_quote["pb"]
                                if not b.get("pe_ttm") and historical_quote.get("pe_ttm"):
                                    b["pe_ttm"] = historical_quote["pe_ttm"]
                                logger.info(f"âœ… ä½¿ç”¨å†å²æ•°æ®å¡«å……: PE={b.get('pe')}, PB={b.get('pb')} (æ—¥æœŸ: {historical_quote.get('trade_date')})")
                        except Exception as e:
                            logger.warning(f"âš ï¸ è·å–å†å²PE/PBå¤±è´¥: {e}")

                    logger.info(f"âœ… å®æ—¶è·å–æˆåŠŸ: {code6} - {b.get('name')} (PE: {b.get('pe')}, PB: {b.get('pb')}, å¸‚å€¼: {b.get('total_mv')})")
                else:
                    raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"æœªæ‰¾åˆ°è‚¡ç¥¨ {code6} çš„ä¿¡æ¯")
            except Exception as e:
                logger.error(f"âŒ å®æ—¶è·å–å¤±è´¥: {code6}, é”™è¯¯: {e}")
                raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯: {str(e)}")

    # 2. å°è¯•ä» stock_financial_data è·å–æœ€æ–°è´¢åŠ¡æŒ‡æ ‡
    # ğŸ”¥ æŒ‰æ•°æ®æºä¼˜å…ˆçº§æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æŒ‰æ—¶é—´æˆ³ï¼Œé¿å…æ··ç”¨ä¸åŒæ•°æ®æºçš„æ•°æ®
    financial_data = None
    try:
        # è·å–æ•°æ®æºä¼˜å…ˆçº§é…ç½®
        from app.core.unified_config import UnifiedConfigManager
        config = UnifiedConfigManager()
        data_source_configs = await config.get_data_source_configs_async()

        # æå–å¯ç”¨çš„æ•°æ®æºï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        enabled_sources = [
            ds.type.lower() for ds in data_source_configs
            if ds.enabled and ds.type.lower() in ['tushare', 'akshare', 'baostock']
        ]

        if not enabled_sources:
            enabled_sources = ['tushare', 'akshare', 'baostock']

        # æŒ‰æ•°æ®æºä¼˜å…ˆçº§æŸ¥è¯¢è´¢åŠ¡æ•°æ®
        for data_source in enabled_sources:
            financial_data = await db["stock_financial_data"].find_one(
                {"$or": [{"symbol": code6}, {"code": code6}], "data_source": data_source},
                {"_id": 0},
                sort=[("report_period", -1)]  # æŒ‰æŠ¥å‘ŠæœŸé™åºï¼Œè·å–è¯¥æ•°æ®æºçš„æœ€æ–°æ•°æ®
            )
            if financial_data:
                logger.info(f"âœ… ä½¿ç”¨æ•°æ®æº {data_source} çš„è´¢åŠ¡æ•°æ® (æŠ¥å‘ŠæœŸ: {financial_data.get('report_period')})")
                break

        if not financial_data:
            logger.warning(f"âš ï¸ æ•°æ®åº“æœªæ‰¾åˆ° {code6} çš„è´¢åŠ¡æ•°æ®ï¼Œå°è¯•ä» AKShare å®æ—¶è·å–...")
            try:
                # ğŸ”¥ Fallback Mechanism: Fetch from AKShare directly
                from typing import List, Dict, Any
                
                # Helper to extract value from AKShare records list (Mirroring api.py logic)
                def get_val(records: List[Dict], key_list: List[str]) -> Any:
                    if not records: return None
                    for r in records:
                        label = r.get('æŒ‡æ ‡') or r.get('item') or r.get('é¡¹ç›®') or r.get('é¡¹ç›®è¯´æ˜')
                        if label in key_list:
                            # Extract data columns (excluding labels)
                            data_keys = [k for k in r.keys() if k.isdigit()]
                            # Sort keys numerically (dates) to find latest
                            date_keys = sorted(data_keys, reverse=True)
                            if date_keys: return r.get(date_keys[0])
                    return None

                df_main = await asyncio.to_thread(ak.stock_financial_abstract, symbol=code6)

                if df_main is not None and not df_main.empty:
                    main_recs = df_main.to_dict('records')

                    # Construct a temporary financial_data object
                    financial_data = {
                        'eps': get_val(main_recs, ['åŸºæœ¬æ¯è‚¡æ”¶ç›Š', 'æ¯è‚¡æ”¶ç›Š']),
                        'bvps': get_val(main_recs, ['æ¯è‚¡å‡€èµ„äº§']),
                        'roe': get_val(main_recs, ['å‡€èµ„äº§æ”¶ç›Šç‡(ROE)', 'å‡€èµ„äº§æ”¶ç›Šç‡']),
                        'roa': get_val(main_recs, ['æ€»èµ„äº§æŠ¥é…¬ç‡', 'ROA']), # Try to get ROA
                        'revenue': get_val(main_recs, ['è¥ä¸šæ€»æ”¶å…¥', 'è¥ä¸šæ”¶å…¥']),
                        'net_profit': get_val(main_recs, ['å½’æ¯å‡€åˆ©æ¶¦', 'å‡€åˆ©æ¶¦']),
                        'net_profit_parent': get_val(main_recs, ['å½’æ¯å‡€åˆ©æ¶¦']), # Alias
                        'gross_margin': get_val(main_recs, ['æ¯›åˆ©ç‡', 'é”€å”®æ¯›åˆ©ç‡']),
                        'net_profit_margin': get_val(main_recs, ['å‡€åˆ©ç‡', 'é”€å”®å‡€åˆ©ç‡']), # Try to get Net Margin
                        'debt_to_assets': get_val(main_recs, ['èµ„äº§è´Ÿå€ºç‡']),
                        'report_period': 'realtime_fallback',
                        'source': 'akshare_fallback'
                    }

                    logger.info(f"âœ… ä» AKShare å®æ—¶è·å–è´¢åŠ¡æ•°æ®æˆåŠŸ (Source: {financial_data['source']})")
                else:
                    logger.warning(f"âš ï¸ AKShare å®æ—¶è·å–è´¢åŠ¡æ•°æ®ä¸ºç©º: {code6}")
            except Exception as e:
                logger.error(f"âŒ AKShare å®æ—¶è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
    except Exception as e:
        logger.error(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")

    # 3. è·å–å®æ—¶PE/PBï¼ˆä¼˜å…ˆä½¿ç”¨å®æ—¶è®¡ç®—ï¼‰
    from tradingagents.dataflows.realtime_metrics import get_pe_pb_with_fallback

    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çš„å®æ—¶è®¡ç®—
    realtime_metrics = await asyncio.to_thread(
        get_pe_pb_with_fallback,
        code6,
        db.client
    )

    # ğŸ”¥ å¦‚æœå®æ—¶PE/PBä¸ºç©ºï¼Œå°è¯•ä»å†å²æ•°æ®è·å–æœ€è¿‘çš„PE/PBï¼ˆå‘¨æœ«/èŠ‚å‡æ—¥fallbackï¼‰
    if not realtime_metrics.get("pe") or not realtime_metrics.get("pb"):
        logger.info(f"âš ï¸ å®æ—¶PE/PBä¸ºç©ºï¼Œå°è¯•ä»å†å²è¡Œæƒ…æ•°æ®è·å–: {code6}")
        try:
            # ä» stock_daily_quotes è·å–æœ€è¿‘çš„PE/PBæ•°æ®
            historical_quote = await db["stock_daily_quotes"].find_one(
                {"code": code6},
                {"pe": 1, "pb": 1, "pe_ttm": 1, "trade_date": 1},
                sort=[("trade_date", -1)]
            )
            if historical_quote:
                fallback_used = False
                if not realtime_metrics.get("pe") and historical_quote.get("pe"):
                    realtime_metrics["pe"] = historical_quote["pe"]
                    realtime_metrics["pe_source"] = f"historical_{historical_quote.get('trade_date')}"
                    fallback_used = True
                if not realtime_metrics.get("pb") and historical_quote.get("pb"):
                    realtime_metrics["pb"] = historical_quote["pb"]
                    fallback_used = True
                if not realtime_metrics.get("pe_ttm") and historical_quote.get("pe_ttm"):
                    realtime_metrics["pe_ttm"] = historical_quote["pe_ttm"]
                    fallback_used = True
                if fallback_used:
                    logger.info(f"âœ… ä½¿ç”¨å†å²æ•°æ®å¡«å……: PE={realtime_metrics.get('pe')}, PB={realtime_metrics.get('pb')}, PE_TTM={realtime_metrics.get('pe_ttm')} (æ—¥æœŸ: {historical_quote.get('trade_date')})")
            else:
                # ğŸ”¥ æ•°æ®åº“ä¹Ÿæ²¡æœ‰ï¼Œæœ€åå°è¯•ä»AKShareè·å–æœ€è¿‘å‡ å¤©çš„å†å²æ•°æ®
                logger.info(f"âš ï¸ æ•°æ®åº“æ— å†å²æ•°æ®ï¼Œå°è¯•ä»AKShareè·å–: {code6}")
                from tradingagents.dataflows.providers.china.akshare import AKShareProvider
                from datetime import datetime, timedelta

                akshare = AKShareProvider()
                # è·å–æœ€è¿‘10å¤©çš„å†å²æ•°æ®ï¼ˆç¡®ä¿èƒ½è·¨è¿‡å‘¨æœ«ï¼‰
                end_date = datetime.now()
                start_date = end_date - timedelta(days=10)

                hist_data = await akshare.get_historical_data(
                    code6,
                    start_date=start_date.strftime("%Y%m%d"),
                    end_date=end_date.strftime("%Y%m%d")
                )

                # æ£€æŸ¥æ˜¯å¦æœ‰è¿”å›æ•°æ®ï¼ˆå¯èƒ½æ˜¯DataFrameæˆ–listï¼‰
                import pandas as pd
                has_data = False
                if hist_data is not None:
                    if isinstance(hist_data, pd.DataFrame):
                        has_data = not hist_data.empty
                    elif isinstance(hist_data, list):
                        has_data = len(hist_data) > 0

                if has_data:
                    # è·å–æœ€æ–°ä¸€å¤©çš„æ•°æ®
                    if isinstance(hist_data, pd.DataFrame):
                        latest_row = hist_data.iloc[-1]
                        latest = {
                            "pe": latest_row.get("pe"),
                            "pb": latest_row.get("pb"),
                            "pe_ttm": latest_row.get("pe_ttm"),
                            "trade_date": latest_row.get("trade_date")
                        }
                    else:
                        latest = hist_data[-1]

                    fallback_used = False
                    if not realtime_metrics.get("pe") and latest.get("pe"):
                        realtime_metrics["pe"] = float(latest["pe"]) if latest["pe"] else None
                        realtime_metrics["pe_source"] = f"akshare_historical_{latest.get('trade_date')}"
                        fallback_used = True
                    if not realtime_metrics.get("pb") and latest.get("pb"):
                        realtime_metrics["pb"] = float(latest["pb"]) if latest["pb"] else None
                        fallback_used = True
                    if not realtime_metrics.get("pe_ttm") and latest.get("pe_ttm"):
                        realtime_metrics["pe_ttm"] = float(latest["pe_ttm"]) if latest["pe_ttm"] else None
                        fallback_used = True
                    if fallback_used:
                        logger.info(f"âœ… ä½¿ç”¨AKShareå†å²æ•°æ®: PE={realtime_metrics.get('pe')}, PB={realtime_metrics.get('pb')} (æ—¥æœŸ: {latest.get('trade_date')})")
                else:
                    logger.warning(f"âš ï¸ AKShareä¹Ÿæ— æ³•è·å–å†å²æ•°æ®: {code6}")
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–å†å²PE/PBå¤±è´¥: {e}")

    # 4. æ„å»ºè¿”å›æ•°æ®
    # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨å®æ—¶å¸‚å€¼ï¼Œé™çº§åˆ° stock_basic_info çš„é™æ€å¸‚å€¼
    realtime_market_cap = realtime_metrics.get("market_cap")  # å®æ—¶å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
    total_mv = realtime_market_cap if realtime_market_cap else b.get("total_mv")

    data = {
        "code": code6,
        "name": b.get("name"),
        "industry": b.get("industry"),  # è¡Œä¸šï¼ˆå¦‚ï¼šé“¶è¡Œã€è½¯ä»¶æœåŠ¡ï¼‰
        "market": b.get("market"),      # äº¤æ˜“æ‰€ï¼ˆå¦‚ï¼šä¸»æ¿ã€åˆ›ä¸šæ¿ï¼‰

        # æ¿å—ä¿¡æ¯ï¼šä½¿ç”¨ market å­—æ®µï¼ˆä¸»æ¿/åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/åŒ—äº¤æ‰€ç­‰ï¼‰
        "sector": b.get("market"),

        # ä¼°å€¼æŒ‡æ ‡ï¼ˆä¼˜å…ˆä½¿ç”¨å®æ—¶è®¡ç®—ï¼Œé™çº§åˆ° stock_basic_infoï¼‰
        "pe": realtime_metrics.get("pe") or b.get("pe"),
        "pb": realtime_metrics.get("pb") or b.get("pb"),
        "pe_ttm": realtime_metrics.get("pe_ttm") or b.get("pe_ttm"),
        "pb_mrq": realtime_metrics.get("pb_mrq") or b.get("pb_mrq"),

        # ğŸ”¥ å¸‚é”€ç‡ï¼ˆPSï¼‰- åŠ¨æ€è®¡ç®—ï¼ˆä½¿ç”¨å®æ—¶å¸‚å€¼ï¼‰
        "ps": None,
        "ps_ttm": None,

        # PE/PB æ•°æ®æ¥æºæ ‡è¯†
        "pe_source": realtime_metrics.get("source", "unknown"),
        "pe_is_realtime": realtime_metrics.get("is_realtime", False),
        "pe_updated_at": realtime_metrics.get("updated_at"),

        # ROEï¼ˆä¼˜å…ˆä» stock_financial_data è·å–ï¼Œå…¶æ¬¡ä» stock_basic_infoï¼‰
        "roe": None,

        # è´Ÿå€ºç‡ï¼ˆä» stock_financial_data è·å–ï¼‰
        "debt_ratio": None,

        # å¸‚å€¼ï¼šä¼˜å…ˆä½¿ç”¨å®æ—¶å¸‚å€¼ï¼Œé™çº§åˆ°é™æ€å¸‚å€¼
        "total_mv": total_mv,
        "circ_mv": b.get("circ_mv"),

        # ğŸ”¥ å¸‚å€¼æ¥æºæ ‡è¯†
        "mv_is_realtime": bool(realtime_market_cap),

        # äº¤æ˜“æŒ‡æ ‡ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
        "turnover_rate": b.get("turnover_rate"),
        "volume_ratio": b.get("volume_ratio"),

        "updated_at": b.get("updated_at"),
    }

    # 5. ä»è´¢åŠ¡æ•°æ®ä¸­æå– ROEã€è´Ÿå€ºç‡å’Œè®¡ç®— PS
    if financial_data:
        # ROEï¼ˆå‡€èµ„äº§æ”¶ç›Šç‡ï¼‰
        indicators = financial_data.get("financial_indicators") or {}
        if indicators:
            data["roe"] = indicators.get("roe")
            data["debt_ratio"] = indicators.get("debt_to_assets")

        # å¦‚æœ financial_indicators ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»é¡¶å±‚å­—æ®µè·å–
        if data["roe"] is None:
            data["roe"] = financial_data.get("roe")
        if data["debt_ratio"] is None:
            data["debt_ratio"] = financial_data.get("debt_to_assets")

        # ğŸ”¥ Map missing core financial fields
        data["revenue"] = financial_data.get("revenue")
        data["net_profit"] = financial_data.get("net_profit")
        data["net_profit_parent"] = financial_data.get("net_profit_parent")
        data["gross_margin"] = financial_data.get("gross_margin")
        data["net_profit_margin"] = financial_data.get("net_profit_margin")
        
        # Extract per-share data (check both root and indicators)
        data["eps"] = financial_data.get("eps") or indicators.get("eps")
        data["bvps"] = financial_data.get("bvps") or indicators.get("bvps") 
        data["roa"] = financial_data.get("roa") or indicators.get("roa")

        # ğŸ”¥ åŠ¨æ€è®¡ç®— PSï¼ˆå¸‚é”€ç‡ï¼‰- ä½¿ç”¨å®æ—¶å¸‚å€¼
        # ä¼˜å…ˆä½¿ç”¨ TTM è¥ä¸šæ”¶å…¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å•æœŸè¥ä¸šæ”¶å…¥
        revenue_ttm = financial_data.get("revenue_ttm")
        revenue = financial_data.get("revenue")
        revenue_for_ps = revenue_ttm if revenue_ttm and revenue_ttm > 0 else revenue

        if revenue_for_ps and revenue_for_ps > 0:
            # ğŸ”¥ ä½¿ç”¨å®æ—¶å¸‚å€¼ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨é™æ€å¸‚å€¼
            if total_mv and total_mv > 0:
                # è¥ä¸šæ”¶å…¥å•ä½ï¼šå…ƒï¼Œéœ€è¦è½¬æ¢ä¸ºäº¿å…ƒ
                revenue_yi = revenue_for_ps / 100000000
                ps_calculated = total_mv / revenue_yi
                data["ps"] = round(ps_calculated, 2)
                data["ps_ttm"] = round(ps_calculated, 2) if revenue_ttm else None

    # 6. å¦‚æœè´¢åŠ¡æ•°æ®ä¸­æ²¡æœ‰ ROEï¼Œä½¿ç”¨ stock_basic_info ä¸­çš„
    if data["roe"] is None:
        data["roe"] = b.get("roe")

    return ok(data)


@router.get("/{code}/kline", response_model=dict)
async def get_kline(
    code: str,
    period: str = "day",
    limit: int = 120,
    adj: str = "none",
    force_refresh: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰"),
    current_user: dict = Depends(get_current_user)
):
    """
    è·å–Kçº¿æ•°æ®ï¼ˆæ”¯æŒAè‚¡/æ¸¯è‚¡/ç¾è‚¡ï¼‰

    period: day/week/month/5m/15m/30m/60m
    adj: none/qfq/hfq
    force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰

    ğŸ”¥ æ–°å¢åŠŸèƒ½ï¼šå½“å¤©å®æ—¶Kçº¿æ•°æ®
    - äº¤æ˜“æ—¶é—´å†…ï¼ˆ09:30-15:00ï¼‰ï¼šä» market_quotes è·å–å®æ—¶æ•°æ®
    - æ”¶ç›˜åï¼šæ£€æŸ¥å†å²æ•°æ®æ˜¯å¦æœ‰å½“å¤©æ•°æ®ï¼Œæ²¡æœ‰åˆ™ä» market_quotes è·å–
    """
    import logging
    from datetime import datetime, timedelta, time as dtime
    from zoneinfo import ZoneInfo
    logger = logging.getLogger(__name__)

    valid_periods = {"day","week","month","5m","15m","30m","60m"}
    if period not in valid_periods:
        raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„period: {period}")

    # æ£€æµ‹å¸‚åœºç±»å‹
    market, normalized_code = _detect_market_and_code(code)

    # æ¸¯è‚¡å’Œç¾è‚¡ï¼šä½¿ç”¨æ–°æœåŠ¡
    if market in ['HK', 'US']:
        from app.services.foreign_stock_service import ForeignStockService

        db = get_mongo_db()  # ä¸éœ€è¦ awaitï¼Œç›´æ¥è¿”å›æ•°æ®åº“å¯¹è±¡
        service = ForeignStockService(db=db)

        try:
            kline_data = await service.get_kline(market, normalized_code, period, limit, force_refresh)
            return ok(data={
                'code': normalized_code,
                'period': period,
                'items': kline_data,
                'source': 'cache_or_api'
            })
        except Exception as e:
            logger.error(f"è·å–{market}è‚¡ç¥¨{code}Kçº¿æ•°æ®å¤±è´¥: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"è·å–Kçº¿æ•°æ®å¤±è´¥: {str(e)}"
            )

    # Aè‚¡ï¼šä½¿ç”¨ç°æœ‰é€»è¾‘
    code_padded = normalized_code
    adj_norm = None if adj in (None, "none", "", "null") else adj
    items = None
    source = None

    # å‘¨æœŸæ˜ å°„ï¼šå‰ç«¯ -> MongoDB
    period_map = {
        "day": "daily",
        "week": "weekly",
        "month": "monthly",
        "5m": "5min",
        "15m": "15min",
        "30m": "30min",
        "60m": "60min"
    }
    mongodb_period = period_map.get(period, "daily")

    # è·å–å½“å‰æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
    from app.core.config import settings
    tz = ZoneInfo(settings.TIMEZONE)
    now = datetime.now(tz)
    today_str_yyyymmdd = now.strftime("%Y%m%d")  # æ ¼å¼ï¼š20251028ï¼ˆç”¨äºæŸ¥è¯¢ï¼‰
    today_str_formatted = now.strftime("%Y-%m-%d")  # æ ¼å¼ï¼š2025-10-28ï¼ˆç”¨äºè¿”å›ï¼‰

    # 1. ä¼˜å…ˆä» MongoDB ç¼“å­˜è·å–
    try:
        from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
        adapter = get_mongodb_cache_adapter()

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = now.strftime("%Y-%m-%d")
        start_date = (now - timedelta(days=limit * 2)).strftime("%Y-%m-%d")

        logger.info(f"ğŸ” å°è¯•ä» MongoDB è·å– K çº¿æ•°æ®: {code_padded}, period={period} (MongoDB: {mongodb_period}), limit={limit}")
        df = adapter.get_historical_data(code_padded, start_date, end_date, period=mongodb_period)

        if df is not None and not df.empty:
            # è½¬æ¢ DataFrame ä¸ºåˆ—è¡¨æ ¼å¼
            items = []
            for _, row in df.tail(limit).iterrows():
                items.append({
                    "time": row.get("trade_date", row.get("date", "")),  # å‰ç«¯æœŸæœ› time å­—æ®µ
                    "open": float(row.get("open", 0)),
                    "high": float(row.get("high", 0)),
                    "low": float(row.get("low", 0)),
                    "close": float(row.get("close", 0)),
                    "volume": float(row.get("volume", row.get("vol", 0))),
                    "amount": float(row.get("amount", 0)) if "amount" in row else None,
                })
            source = "mongodb"
            logger.info(f"âœ… ä» MongoDB è·å–åˆ° {len(items)} æ¡ K çº¿æ•°æ®")
    except Exception as e:
        logger.warning(f"âš ï¸ MongoDB è·å– K çº¿å¤±è´¥: {e}")

    # 2. å¦‚æœ MongoDB æ²¡æœ‰æ•°æ®ï¼Œé™çº§åˆ°å¤–éƒ¨ APIï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
    if not items:
        logger.info(f"ğŸ“¡ MongoDB æ— æ•°æ®ï¼Œé™çº§åˆ°å¤–éƒ¨ API")
        try:
            import asyncio
            from app.services.data_sources.manager import DataSourceManager

            mgr = DataSourceManager()
            # æ·»åŠ  10 ç§’è¶…æ—¶ä¿æŠ¤
            items, source = await asyncio.wait_for(
                asyncio.to_thread(mgr.get_kline_with_fallback, code_padded, period, limit, adj_norm),
                timeout=10.0
            )
        except asyncio.TimeoutError:
            logger.error(f"âŒ å¤–éƒ¨ API è·å– K çº¿è¶…æ—¶ï¼ˆ10ç§’ï¼‰")
            raise HTTPException(status_code=504, detail="è·å–Kçº¿æ•°æ®è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except Exception as e:
            logger.error(f"âŒ å¤–éƒ¨ API è·å– K çº¿å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"è·å–Kçº¿æ•°æ®å¤±è´¥: {str(e)}")

    # ğŸ”¥ 3. æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ å½“å¤©å®æ—¶æ•°æ®ï¼ˆä»…é’ˆå¯¹æ—¥çº¿ï¼‰
    if period == "day" and items:
        try:
            # æ£€æŸ¥å†å²æ•°æ®ä¸­æ˜¯å¦å·²æœ‰å½“å¤©çš„æ•°æ®ï¼ˆæ”¯æŒä¸¤ç§æ—¥æœŸæ ¼å¼ï¼‰
            has_today_data = any(
                item.get("time") in [today_str_yyyymmdd, today_str_formatted]
                for item in items
            )

            # åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…æˆ–æ”¶ç›˜åç¼“å†²æœŸ
            current_time = now.time()
            is_weekday = now.weekday() < 5  # å‘¨ä¸€åˆ°å‘¨äº”

            # äº¤æ˜“æ—¶é—´ï¼š9:30-11:30, 13:00-15:00
            # æ”¶ç›˜åç¼“å†²æœŸï¼š15:00-15:30ï¼ˆç¡®ä¿è·å–åˆ°æ”¶ç›˜ä»·ï¼‰
            is_trading_time = (
                is_weekday and (
                    (dtime(9, 30) <= current_time <= dtime(11, 30)) or
                    (dtime(13, 0) <= current_time <= dtime(15, 30))
                )
            )

            # ğŸ”¥ åªåœ¨äº¤æ˜“æ—¶é—´æˆ–æ”¶ç›˜åç¼“å†²æœŸå†…æ‰æ·»åŠ å®æ—¶æ•°æ®
            # éäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ã€èŠ‚å‡æ—¥ï¼‰ä¸æ·»åŠ å®æ—¶æ•°æ®
            should_fetch_realtime = is_trading_time

            if should_fetch_realtime:
                logger.info(f"ğŸ”¥ å°è¯•ä» market_quotes è·å–å½“å¤©å®æ—¶æ•°æ®: {code_padded} (äº¤æ˜“æ—¶é—´: {is_trading_time}, å·²æœ‰å½“å¤©æ•°æ®: {has_today_data})")

                db = get_mongo_db()
                market_quotes_coll = db["market_quotes"]

                # æŸ¥è¯¢å½“å¤©çš„å®æ—¶è¡Œæƒ…
                realtime_quote = await market_quotes_coll.find_one({"code": code_padded})

                if realtime_quote:
                    # ğŸ”¥ æ„é€ å½“å¤©çš„Kçº¿æ•°æ®ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æ—¥æœŸæ ¼å¼ YYYY-MM-DDï¼‰
                    today_kline = {
                        "time": today_str_formatted,  # ğŸ”¥ ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ï¼Œä¸å†å²æ•°æ®ä¿æŒä¸€è‡´
                        "open": float(realtime_quote.get("open", 0)),
                        "high": float(realtime_quote.get("high", 0)),
                        "low": float(realtime_quote.get("low", 0)),
                        "close": float(realtime_quote.get("close", 0)),
                        "volume": float(realtime_quote.get("volume", 0)),
                        "amount": float(realtime_quote.get("amount", 0)),
                    }

                    # å¦‚æœå†å²æ•°æ®ä¸­å·²æœ‰å½“å¤©æ•°æ®ï¼Œæ›¿æ¢ï¼›å¦åˆ™è¿½åŠ 
                    if has_today_data:
                        # æ›¿æ¢æœ€åä¸€æ¡æ•°æ®ï¼ˆå‡è®¾æœ€åä¸€æ¡æ˜¯å½“å¤©çš„ï¼‰
                        items[-1] = today_kline
                        logger.info(f"âœ… æ›¿æ¢å½“å¤©Kçº¿æ•°æ®: {code_padded}")
                    else:
                        # è¿½åŠ åˆ°æœ«å°¾
                        items.append(today_kline)
                        logger.info(f"âœ… è¿½åŠ å½“å¤©Kçº¿æ•°æ®: {code_padded}")

                    source = f"{source}+market_quotes"
                else:
                    logger.warning(f"âš ï¸ market_quotes ä¸­æœªæ‰¾åˆ°å½“å¤©æ•°æ®: {code_padded}")
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–å½“å¤©å®æ—¶æ•°æ®å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰: {e}")

    data = {
        "code": code_padded,
        "period": period,
        "limit": limit,
        "adj": adj if adj else "none",
        "source": source,
        "items": items or []
    }
    return ok(data)


@router.get("/{code}/news", response_model=dict)
async def get_news(code: str, days: int = 30, limit: int = 50, include_announcements: bool = True, current_user: dict = Depends(get_current_user)):
    """è·å–æ–°é—»ä¸å…¬å‘Šï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"""
    from app.services.foreign_stock_service import ForeignStockService
    from app.services.news_data_service import get_news_data_service, NewsQueryParams

    # æ£€æµ‹è‚¡ç¥¨ç±»å‹
    market, normalized_code = _detect_market_and_code(code)

    if market == 'US':
        # ç¾è‚¡ï¼šä½¿ç”¨ ForeignStockService
        service = ForeignStockService()
        result = await service.get_us_news(normalized_code, days=days, limit=limit)
        return ok(result)
    elif market == 'HK':
        # æ¸¯è‚¡ï¼šæš‚æ—¶è¿”å›ç©ºæ•°æ®ï¼ˆTODO: å®ç°æ¸¯è‚¡æ–°é—»ï¼‰
        data = {
            "code": normalized_code,
            "days": days,
            "limit": limit,
            "source": "none",
            "items": []
        }
        return ok(data)
    else:
        # Aè‚¡ï¼šç›´æ¥è°ƒç”¨åŒæ­¥æœåŠ¡çš„æŸ¥è¯¢æ–¹æ³•ï¼ˆåŒ…å«æ™ºèƒ½å›é€€é€»è¾‘ï¼‰
        try:
            logger.info(f"=" * 80)
            logger.info(f"ğŸ“° å¼€å§‹è·å–æ–°é—»: code={code}, normalized_code={normalized_code}, days={days}, limit={limit}")

            # ç›´æ¥ä½¿ç”¨ news_data è·¯ç”±çš„æŸ¥è¯¢é€»è¾‘
            from app.services.news_data_service import get_news_data_service, NewsQueryParams
            from datetime import datetime, timedelta
            from app.worker.akshare_sync_service import get_akshare_sync_service

            service = await get_news_data_service()
            sync_service = await get_akshare_sync_service()

            # è®¡ç®—æ—¶é—´èŒƒå›´
            hours_back = days * 24

            # ğŸ”¥ ä¸è®¾ç½® start_time é™åˆ¶ï¼Œç›´æ¥æŸ¥è¯¢æœ€æ–°çš„ N æ¡æ–°é—»
            # å› ä¸ºæ•°æ®åº“ä¸­çš„æ–°é—»å¯èƒ½ä¸æ˜¯æœ€è¿‘å‡ å¤©çš„ï¼Œè€Œæ˜¯å†å²æ•°æ®
            params = NewsQueryParams(
                symbol=normalized_code,
                limit=limit,
                sort_by="publish_time",
                sort_order=-1
            )

            logger.info(f"ğŸ” æŸ¥è¯¢å‚æ•°: symbol={params.symbol}, limit={params.limit} (ä¸é™åˆ¶æ—¶é—´èŒƒå›´)")

            # 1. å…ˆä»æ•°æ®åº“æŸ¥è¯¢
            logger.info(f"ğŸ“Š æ­¥éª¤1: ä»æ•°æ®åº“æŸ¥è¯¢æ–°é—»...")
            news_list = await service.query_news(params)
            logger.info(f"ğŸ“Š æ•°æ®åº“æŸ¥è¯¢ç»“æœ: è¿”å› {len(news_list)} æ¡æ–°é—»")

            data_source = "database"

            # 2. å¦‚æœæ•°æ®åº“æ²¡æœ‰æ•°æ®ï¼Œè°ƒç”¨åŒæ­¥æœåŠ¡
            if not news_list:
                logger.info(f"âš ï¸ æ•°æ®åº“æ— æ–°é—»æ•°æ®ï¼Œè°ƒç”¨åŒæ­¥æœåŠ¡è·å–: {normalized_code}")
                try:
                    # ğŸ”¥ è°ƒç”¨åŒæ­¥æœåŠ¡ï¼Œä¼ å…¥å•ä¸ªè‚¡ç¥¨ä»£ç åˆ—è¡¨
                    logger.info(f"ğŸ“¡ æ­¥éª¤2: è°ƒç”¨åŒæ­¥æœåŠ¡...")
                    await sync_service.sync_news_data(
                        symbols=[normalized_code],
                        max_news_per_stock=limit,
                        force_update=False,
                        favorites_only=False
                    )

                    # é‡æ–°æŸ¥è¯¢
                    logger.info(f"ğŸ”„ æ­¥éª¤3: é‡æ–°ä»æ•°æ®åº“æŸ¥è¯¢...")
                    news_list = await service.query_news(params)
                    logger.info(f"ğŸ“Š é‡æ–°æŸ¥è¯¢ç»“æœ: è¿”å› {len(news_list)} æ¡æ–°é—»")
                    data_source = "realtime"

                except Exception as e:
                    logger.error(f"âŒ åŒæ­¥æœåŠ¡å¼‚å¸¸: {e}", exc_info=True)

            # è½¬æ¢ä¸ºæ—§æ ¼å¼ï¼ˆå…¼å®¹å‰ç«¯ï¼‰
            logger.info(f"ğŸ”„ æ­¥éª¤4: è½¬æ¢æ•°æ®æ ¼å¼...")
            items = []
            for news in news_list:
                # ğŸ”¥ å°† datetime å¯¹è±¡è½¬æ¢ä¸º ISO å­—ç¬¦ä¸²
                publish_time = news.get("publish_time", "")
                if isinstance(publish_time, datetime):
                    publish_time = publish_time.isoformat()

                items.append({
                    "title": news.get("title", ""),
                    "source": news.get("source", ""),
                    "time": publish_time,
                    "url": news.get("url", ""),
                    "type": "news",
                    "content": news.get("content", ""),
                    "summary": news.get("summary", "")
                })

            logger.info(f"âœ… è½¬æ¢å®Œæˆ: {len(items)} æ¡æ–°é—»")

            data = {
                "code": normalized_code,
                "days": days,
                "limit": limit,
                "include_announcements": include_announcements,
                "source": data_source,
                "items": items
            }

            logger.info(f"ğŸ“¤ æœ€ç»ˆè¿”å›: source={data_source}, items_count={len(items)}")
            logger.info(f"=" * 80)
            return ok(data)

        except Exception as e:
            logger.error(f"âŒ è·å–æ–°é—»å¤±è´¥: {e}", exc_info=True)
            data = {
                "code": normalized_code,
                "days": days,
                "limit": limit,
                "include_announcements": include_announcements,
                "source": None,
                "items": []
            }
            return ok(data)

