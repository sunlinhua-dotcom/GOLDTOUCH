"""
ç»Ÿä¸€åˆ†æå¸ˆ - ä¸¤é˜¶æ®µæ‘˜è¦æ¨¡å¼

ä¼˜åŒ–è¯´æ˜ï¼š
- ç¬¬ä¸€é˜¶æ®µï¼šå¯¹åŸå§‹æ•°æ®è¿›è¡Œæ™ºèƒ½æ‘˜è¦ï¼ˆå‹ç¼©80%+ï¼‰
- ç¬¬äºŒé˜¶æ®µï¼šåŸºäºæ‘˜è¦è¿›è¡Œç»¼åˆåˆ†æ
- æ€»ä½“tokenæ¶ˆè€—é™ä½60-70%
- åˆ†æè´¨é‡æå‡ï¼ˆæ‘˜è¦å»å™ªï¼‰
"""

from langchain_core.messages import HumanMessage, SystemMessage
from tradingagents.utils.logging_manager import get_logger

logger = get_logger(__name__)


def create_unified_analyst(llm, toolkit):
    """
    åˆ›å»ºç»Ÿä¸€åˆ†æå¸ˆèŠ‚ç‚¹ï¼ˆä¸¤é˜¶æ®µæ‘˜è¦æ¨¡å¼ï¼‰

    å·¥ä½œæµç¨‹ï¼š
    1. è·å–4ç±»åŸå§‹æ•°æ®
    2. [ç¬¬ä¸€é˜¶æ®µ] LLMæ‘˜è¦ï¼šå‹ç¼©æ¯ç±»æ•°æ®åˆ°500å­—ä»¥å†…
    3. [ç¬¬äºŒé˜¶æ®µ] LLMåˆ†æï¼šåŸºäºæ‘˜è¦è¾“å‡ºç»“æ„åŒ–åˆ†æç»“æœ
    """

    # ==================== æ‘˜è¦æç¤ºè¯ï¼ˆæç®€ï¼‰ ====================
    SUMMARY_PROMPT = """ä½ æ˜¯æ•°æ®æ‘˜è¦ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹{data_type}æ•°æ®å‹ç¼©ä¸º500å­—ä»¥å†…çš„å…³é”®è¦ç‚¹æ‘˜è¦ã€‚

è¦æ±‚ï¼š
- åªä¿ç•™å¯¹æŠ•èµ„å†³ç­–æœ‰ç”¨çš„æ ¸å¿ƒä¿¡æ¯
- å»é™¤é‡å¤å’Œæ— å…³å†…å®¹
- ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡è¡¨è¾¾
- ä¿ç•™å…³é”®æ•°å­—å’Œæ—¥æœŸ

åŸå§‹æ•°æ®ï¼š
{raw_data}

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦ï¼Œæ— éœ€å¼€åœºç™½ï¼š"""

    # ==================== åˆ†ææç¤ºè¯ï¼ˆç²¾ç®€ï¼‰ ====================
    ANALYSIS_SYSTEM = """ä½ æ˜¯ä¸“ä¸šè‚¡ç¥¨åˆ†æå›¢é˜Ÿã€‚åŸºäºæ‘˜è¦æ•°æ®ï¼Œä»4ä¸ªç»´åº¦è¾“å‡ºJSONåˆ†æï¼š
1. å¸‚åœºæŠ€æœ¯é¢ï¼šè¶‹åŠ¿ã€å…³é”®ä½ã€ç­–ç•¥
2. åŸºæœ¬é¢ä¼°å€¼ï¼šPE/PBã€ä¼°å€¼ç»“è®ºã€ç›®æ ‡ä»·
3. æ–°é—»äº‹ä»¶ï¼šå…³é”®äº‹ä»¶ã€å½±å“ã€é£é™©
4. å¸‚åœºæƒ…ç»ªï¼šæƒ…ç»ªåˆ†æ•°(0-10)ã€æ•£æˆ·/ä¸»åŠ›åŠ¨å‘

è¾“å‡ºè¦æ±‚ï¼šç®€ä½“ä¸­æ–‡ã€çº¯JSONã€åŸºäºçœŸå®æ•°æ®"""

    ANALYSIS_TEMPLATE = """è‚¡ç¥¨ï¼š{ticker} | æ—¥æœŸï¼š{date}

ã€å¸‚åœºæ‘˜è¦ã€‘
{market_summary}

ã€åŸºæœ¬é¢æ‘˜è¦ã€‘
{fundamentals_summary}

ã€æ–°é—»æ‘˜è¦ã€‘
{news_summary}

ã€æƒ…ç»ªæ‘˜è¦ã€‘
{sentiment_summary}

---
è¾“å‡ºJSONæ ¼å¼ï¼š
```json
{{
  "market": {{"view": "è§‚ç‚¹", "trend": "è¶‹åŠ¿", "strategy": "ç­–ç•¥", "risk": "é£é™©"}},
  "fundamentals": {{"pe": "å€¼", "pb": "å€¼", "valuation": "ä½ä¼°/åˆç†/é«˜ä¼°", "target": "ç›®æ ‡ä»·", "action": "ä¹°å…¥/æŒæœ‰/å–å‡º"}},
  "news": {{"event": "å…³é”®äº‹ä»¶", "impact": "å½±å“", "warning": "é£é™©é¢„è­¦"}},
  "sentiment": {{"score": 0-10, "retail": "æ•£æˆ·åŠ¨å‘", "institutional": "ä¸»åŠ›åŠ¨å‘", "contrarian": "é€†å‘å¯ç¤º"}}
}}
```"""

    def _summarize_data(data: str, data_type: str, max_length: int = 3000) -> str:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½æ‘˜è¦åŸå§‹æ•°æ®

        Args:
            data: åŸå§‹æ•°æ®
            data_type: æ•°æ®ç±»å‹ï¼ˆå¸‚åœº/åŸºæœ¬é¢/æ–°é—»/æƒ…ç»ªï¼‰
            max_length: è§¦å‘æ‘˜è¦çš„é˜ˆå€¼

        Returns:
            æ‘˜è¦åçš„æ•°æ®
        """
        if not data or len(str(data)) < 100:
            return str(data) if data else "æš‚æ— æ•°æ®"

        # å¦‚æœæ•°æ®è¾ƒçŸ­ï¼Œç›´æ¥è¿”å›
        data_str = str(data)
        if len(data_str) <= max_length:
            logger.info(f"ğŸ“ [{data_type}] æ•°æ®è¾ƒçŸ­({len(data_str)}å­—ç¬¦)ï¼Œæ— éœ€æ‘˜è¦")
            return data_str

        # éœ€è¦æ‘˜è¦
        logger.info(f"ğŸ“ [{data_type}] å¼€å§‹æ‘˜è¦ï¼ŒåŸå§‹é•¿åº¦: {len(data_str)}å­—ç¬¦")

        try:
            prompt = SUMMARY_PROMPT.format(data_type=data_type, raw_data=data_str[:8000])  # é™åˆ¶è¾“å…¥é•¿åº¦
            response = llm.invoke([HumanMessage(content=prompt)])
            summary = response.content.strip()

            logger.info(f"âœ… [{data_type}] æ‘˜è¦å®Œæˆ: {len(data_str)} -> {len(summary)}å­—ç¬¦ (å‹ç¼©{100-len(summary)*100//len(data_str)}%)")
            return summary

        except Exception as e:
            logger.error(f"âŒ [{data_type}] æ‘˜è¦å¤±è´¥: {e}")
            # é™çº§ï¼šæˆªæ–­è¿”å›
            return data_str[:max_length] + "...(å·²æˆªæ–­)"

    def unified_analyst_node(state):
        """ç»Ÿä¸€åˆ†æå¸ˆèŠ‚ç‚¹ï¼ˆä¸¤é˜¶æ®µæ¨¡å¼ï¼‰"""
        try:
            # è·å–stateå­—æ®µ
            ticker = state.get("company_of_interest")
            date_str = state.get("trade_date")

            logger.info(f"ğŸ¯ [ç»Ÿä¸€åˆ†æ-ä¸¤é˜¶æ®µ] å¼€å§‹åˆ†æ {ticker} - {date_str}")

            # ==================== æ­¥éª¤1ï¼šè·å–åŸå§‹æ•°æ® ====================
            logger.info(f"ğŸ“Š [æ•°æ®è·å–] å¼€å§‹è·å–4ç±»æ•°æ®...")

            # 1. å¸‚åœºæ•°æ®
            market_data = "å¸‚åœºæ•°æ®æš‚æ— "
            try:
                market_data = toolkit.get_stock_market_data_unified(
                    ticker=ticker, start_date=date_str, end_date=date_str
                )
                logger.info(f"âœ… [å¸‚åœºæ•°æ®] è·å–æˆåŠŸï¼Œé•¿åº¦: {len(str(market_data))}å­—ç¬¦")
            except Exception as e:
                logger.error(f"âŒ [å¸‚åœºæ•°æ®] è·å–å¤±è´¥: {e}")

            # 2. åŸºæœ¬é¢æ•°æ®
            fundamentals_data = "åŸºæœ¬é¢æ•°æ®æš‚æ— "
            try:
                fundamentals_data = toolkit.get_stock_fundamentals_unified(
                    ticker=ticker, start_date=date_str, end_date=date_str
                )
                logger.info(f"âœ… [åŸºæœ¬é¢æ•°æ®] è·å–æˆåŠŸï¼Œé•¿åº¦: {len(str(fundamentals_data))}å­—ç¬¦")
            except Exception as e:
                logger.error(f"âŒ [åŸºæœ¬é¢æ•°æ®] è·å–å¤±è´¥: {e}")

            # 3. æ–°é—»æ•°æ®
            news_data = "æ–°é—»æ•°æ®æš‚æ— "
            try:
                from tradingagents.tools.unified_news_tool import create_unified_news_tool
                news_tool = create_unified_news_tool(toolkit)
                news_data = news_tool(stock_code=ticker, max_news=10)
                logger.info(f"âœ… [æ–°é—»æ•°æ®] è·å–æˆåŠŸï¼Œé•¿åº¦: {len(str(news_data))}å­—ç¬¦")
            except Exception as e:
                logger.error(f"âŒ [æ–°é—»æ•°æ®] è·å–å¤±è´¥: {e}")

            # 4. æƒ…ç»ªæ•°æ®
            sentiment_data = "æƒ…ç»ªæ•°æ®æš‚æ— "
            try:
                sentiment_data = toolkit.get_stock_sentiment_unified(
                    ticker=ticker, curr_date=date_str
                )
                logger.info(f"âœ… [æƒ…ç»ªæ•°æ®] è·å–æˆåŠŸï¼Œé•¿åº¦: {len(str(sentiment_data))}å­—ç¬¦")
            except Exception as e:
                logger.error(f"âŒ [æƒ…ç»ªæ•°æ®] è·å–å¤±è´¥: {e}")

            # è®¡ç®—åŸå§‹æ•°æ®æ€»å¤§å°
            total_raw_size = sum(len(str(d)) for d in [market_data, fundamentals_data, news_data, sentiment_data])
            logger.info(f"ğŸ“Š [åŸå§‹æ•°æ®] æ€»å¤§å°: {total_raw_size}å­—ç¬¦")

            # ==================== æ­¥éª¤2ï¼šç¬¬ä¸€é˜¶æ®µ - æ•°æ®æ‘˜è¦ ====================
            logger.info(f"ğŸ”„ [ç¬¬ä¸€é˜¶æ®µ] å¼€å§‹æ•°æ®æ‘˜è¦...")

            market_summary = _summarize_data(market_data, "å¸‚åœºæ•°æ®")
            fundamentals_summary = _summarize_data(fundamentals_data, "åŸºæœ¬é¢æ•°æ®")
            news_summary = _summarize_data(news_data, "æ–°é—»æ•°æ®")
            sentiment_summary = _summarize_data(sentiment_data, "æƒ…ç»ªæ•°æ®")

            total_summary_size = sum(len(s) for s in [market_summary, fundamentals_summary, news_summary, sentiment_summary])
            compression_rate = 100 - (total_summary_size * 100 // max(total_raw_size, 1))
            logger.info(f"âœ… [ç¬¬ä¸€é˜¶æ®µå®Œæˆ] æ‘˜è¦æ€»å¤§å°: {total_summary_size}å­—ç¬¦ï¼Œå‹ç¼©ç‡: {compression_rate}%")

            # ==================== æ­¥éª¤3ï¼šç¬¬äºŒé˜¶æ®µ - ç»¼åˆåˆ†æ ====================
            logger.info(f"ğŸ¤– [ç¬¬äºŒé˜¶æ®µ] å¼€å§‹ç»¼åˆåˆ†æ...")

            analysis_prompt = ANALYSIS_TEMPLATE.format(
                ticker=ticker,
                date=date_str,
                market_summary=market_summary,
                fundamentals_summary=fundamentals_summary,
                news_summary=news_summary,
                sentiment_summary=sentiment_summary
            )

            messages = [
                SystemMessage(content=ANALYSIS_SYSTEM),
                HumanMessage(content=analysis_prompt)
            ]

            response = llm.invoke(messages)
            logger.info(f"âœ… [ç¬¬äºŒé˜¶æ®µå®Œæˆ] åˆ†æç»“æœé•¿åº¦: {len(response.content)}å­—ç¬¦")

            # ==================== æ­¥éª¤4ï¼šè§£æç»“æœ ====================
            import json

            def format_report(report_dict: dict, report_type: str) -> str:
                """å°†åˆ†æç»“æœå­—å…¸è½¬æ¢ä¸ºæ ¼å¼åŒ–å­—ç¬¦ä¸²"""
                if not report_dict:
                    return f"{report_type}ï¼šæš‚æ— æ•°æ®"
                lines = [f"=== {report_type} ==="]
                for key, value in report_dict.items():
                    if isinstance(value, dict):
                        lines.append(f"\nã€{key}ã€‘")
                        for sub_key, sub_value in value.items():
                            lines.append(f"  - {sub_key}: {sub_value}")
                    else:
                        lines.append(f"â€¢ {key}: {value}")
                return "\n".join(lines)

            try:
                content = response.content
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()

                analysis_result = json.loads(content)

                # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆå…¼å®¹åç»­èŠ‚ç‚¹ï¼‰
                market_report_str = format_report(analysis_result.get("market", {}), "å¸‚åœºæŠ€æœ¯é¢åˆ†æ")
                fundamentals_report_str = format_report(analysis_result.get("fundamentals", {}), "åŸºæœ¬é¢ä¼°å€¼åˆ†æ")
                news_report_str = format_report(analysis_result.get("news", {}), "æ–°é—»äº‹ä»¶åˆ†æ")
                sentiment_report_str = format_report(analysis_result.get("sentiment", {}), "å¸‚åœºæƒ…ç»ªåˆ†æ")

                logger.info(f"âœ… [è§£æå®Œæˆ] 4ç±»æŠ¥å‘Šå·²ç”Ÿæˆ")

                return {
                    "messages": state["messages"] + [response],
                    "market_report": market_report_str,
                    "fundamentals_report": fundamentals_report_str,
                    "news_report": news_report_str,
                    "sentiment_report": sentiment_report_str,
                    "unified_analysis_complete": True,
                    # è®°å½•å‹ç¼©ç»Ÿè®¡
                    "_compression_stats": {
                        "raw_size": total_raw_size,
                        "summary_size": total_summary_size,
                        "compression_rate": f"{compression_rate}%"
                    }
                }

            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ [JSONè§£æ] å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬: {e}")
                return {
                    "messages": state["messages"] + [response],
                    "market_report": response.content,
                    "fundamentals_report": response.content,
                    "news_report": response.content,
                    "sentiment_report": response.content,
                    "unified_analysis_complete": True
                }

        except Exception as e:
            logger.error(f"âŒ [ç»Ÿä¸€åˆ†æ] å¤±è´¥: {e}", exc_info=True)
            error_msg = f"ç»Ÿä¸€åˆ†æå¤±è´¥: {str(e)}"
            return {
                "messages": state["messages"] + [SystemMessage(content=error_msg)],
                "market_report": error_msg,
                "fundamentals_report": error_msg,
                "news_report": error_msg,
                "sentiment_report": error_msg,
                "unified_analysis_complete": False
            }

    return unified_analyst_node
